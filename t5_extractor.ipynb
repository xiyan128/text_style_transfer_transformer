{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":31106,"status":"ok","timestamp":1646888170516,"user":{"displayName":"Xiyan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcg993ydhhc_E_jLjU0Fbj_ESzMgkFXC4i6rHZEA=s64","userId":"16542303003688506111"},"user_tz":480},"id":"1xTXy4DVi4ok","outputId":"9abdfe8f-6710-4346-b8cd-783fba8d42db"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting transformers\n","  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n","\u001b[K     |████████████████████████████████| 3.8 MB 4.0 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 56.9 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 58.4 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 5.0 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Collecting tokenizers!=0.11.3,>=0.11.1\n","  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n","\u001b[K     |████████████████████████████████| 6.5 MB 36.8 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.11.6 transformers-4.17.0\n","Collecting pytorch_lightning\n","  Downloading pytorch_lightning-1.5.10-py3-none-any.whl (527 kB)\n","\u001b[K     |████████████████████████████████| 527 kB 3.2 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (4.63.0)\n","Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n","  Downloading fsspec-2022.2.0-py3-none-any.whl (134 kB)\n","\u001b[K     |████████████████████████████████| 134 kB 59.8 MB/s \n","\u001b[?25hRequirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (6.0)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.21.5)\n","Collecting setuptools==59.5.0\n","  Downloading setuptools-59.5.0-py3-none-any.whl (952 kB)\n","\u001b[K     |████████████████████████████████| 952 kB 47.5 MB/s \n","\u001b[?25hCollecting future>=0.17.1\n","  Downloading future-0.18.2.tar.gz (829 kB)\n","\u001b[K     |████████████████████████████████| 829 kB 54.9 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (3.10.0.2)\n","Collecting pyDeprecate==0.3.1\n","  Downloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\n","Requirement already satisfied: torch>=1.7.* in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.10.0+cu111)\n","Collecting torchmetrics>=0.4.1\n","  Downloading torchmetrics-0.7.2-py3-none-any.whl (397 kB)\n","\u001b[K     |████████████████████████████████| 397 kB 58.1 MB/s \n","\u001b[?25hRequirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (2.8.0)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.23.0)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 59.8 MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch_lightning) (3.0.7)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.4.6)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.8.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.6.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.3.6)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.17.3)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.35.0)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.44.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.37.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.0.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch_lightning) (1.15.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.2.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (4.11.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (3.7.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.4.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.24.3)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (3.2.0)\n","Collecting asynctest==0.13.0\n","  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n","Collecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.0.12)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (21.4.0)\n","Collecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n","\u001b[K     |████████████████████████████████| 94 kB 2.7 MB/s \n","\u001b[?25hCollecting yarl<2.0,>=1.0\n","  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 66.6 MB/s \n","\u001b[?25hCollecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","\u001b[K     |████████████████████████████████| 144 kB 57.4 MB/s \n","\u001b[?25hBuilding wheels for collected packages: future\n","  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=d6aa91eb0996ebb0f55b1323837bec249a1bad51d097e0f179fa889810b30faf\n","  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n","Successfully built future\n","Installing collected packages: setuptools, multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, pyDeprecate, fsspec, aiohttp, torchmetrics, future, pytorch-lightning\n","  Attempting uninstall: setuptools\n","    Found existing installation: setuptools 57.4.0\n","    Uninstalling setuptools-57.4.0:\n","      Successfully uninstalled setuptools-57.4.0\n","  Attempting uninstall: future\n","    Found existing installation: future 0.16.0\n","    Uninstalling future-0.16.0:\n","      Successfully uninstalled future-0.16.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 frozenlist-1.3.0 fsspec-2022.2.0 future-0.18.2 multidict-6.0.2 pyDeprecate-0.3.1 pytorch-lightning-1.5.10 setuptools-59.5.0 torchmetrics-0.7.2 yarl-1.7.2\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pkg_resources"]}}},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 3.2 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.96\n"]}],"source":["!pip install transformers\n","!pip install pytorch_lightning\n","!pip install sentencepiece"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":7958,"status":"ok","timestamp":1646888178468,"user":{"displayName":"Xiyan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcg993ydhhc_E_jLjU0Fbj_ESzMgkFXC4i6rHZEA=s64","userId":"16542303003688506111"},"user_tz":480},"id":"b4cYkUwQjEOj","outputId":"6cf0331e-5ceb-4191-daa9-d68a688f179d"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'1.10.0+cu111'"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["from torch.utils.data import Dataset , DataLoader\n","import pytorch_lightning as pl\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from collections import OrderedDict\n","from itertools import chain\n","import ast\n","from transformers import T5TokenizerFast\n","from pytorch_lightning.core.lightning import LightningModule\n","from pytorch_lightning import Trainer\n","torch.version.__version__"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22160,"status":"ok","timestamp":1646888200620,"user":{"displayName":"Xiyan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcg993ydhhc_E_jLjU0Fbj_ESzMgkFXC4i6rHZEA=s64","userId":"16542303003688506111"},"user_tz":480},"id":"foO3yY9wjB5H","outputId":"5f958c35-31aa-4dde-cb82-744886293b60"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","root = \"drive/MyDrive/lign167_data\""]},{"cell_type":"markdown","metadata":{"id":"284qZEqIw0fq"},"source":["# 1. Prepare Data"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":3295,"status":"ok","timestamp":1646888203911,"user":{"displayName":"Xiyan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcg993ydhhc_E_jLjU0Fbj_ESzMgkFXC4i6rHZEA=s64","userId":"16542303003688506111"},"user_tz":480},"id":"U5q0pcNOjy4N"},"outputs":[],"source":["raw_data = pd.read_csv(f\"{root}/amazon_188703.csv\", converters={1:ast.literal_eval})\n","raw_data = raw_data[[\"splitted\"]]"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":473},"executionInfo":{"elapsed":225,"status":"ok","timestamp":1646888204130,"user":{"displayName":"Xiyan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcg993ydhhc_E_jLjU0Fbj_ESzMgkFXC4i6rHZEA=s64","userId":"16542303003688506111"},"user_tz":480},"id":"dQkH0VMRkQsQ","outputId":"e3c266a1-8902-4e81-efc4-a69dee57afab"},"outputs":[{"name":"stdout","output_type":"stream","text":["344808\n"]},{"data":{"text/html":["\n","  <div id=\"df-ebc52452-8a0b-4478-a264-449998b9186b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>splitted</th>\n","      <th>len</th>\n","    </tr>\n","    <tr>\n","      <th>cumlen</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[Excellent game, worked really well!, Makes me think quickly...good brain exercise!]</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>[The Bible for Alexa is a great addition., Along with getting my daily dose from the scripture of the day, I can hear God's word anytime.]</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>[I like it but I don't love it., I wish Alexa could just open my Verse of the day more easily , she seems to never understand ., I have to be so s...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>[Very useful skill and much needed., Setup is pretty easy and works reliably]</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>[Takes a lil time to get everything set up but once its done, everything works like a charm., U can even back up your remotes from the app to open...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>344800</th>\n","      <td>[It was hard to keep the names of the characters straight., And the development of the characters certainly needed more development., But the acti...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>344802</th>\n","      <td>[Another enjoyable read from Catherine Bybee., The hard part is putting it down!!, Great characters that make you want to follow their journey.]</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>344803</th>\n","      <td>[I was never quite sure who was going to die, Booker or Dani., I recommend the book for a rainy weekend.]</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>344804</th>\n","      <td>[i really like the way the author leads you in multiple directions as to whom the \"client\" is., fun book to read during my breaks.]</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>344807</th>\n","      <td>[I've read three of Bobby Cole's books now, and this latest one didn't disappoint me., It was an action packed mystery thriller in a local souther...</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>188702 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ebc52452-8a0b-4478-a264-449998b9186b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ebc52452-8a0b-4478-a264-449998b9186b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ebc52452-8a0b-4478-a264-449998b9186b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                                                                                                                                     splitted  \\\n","cumlen                                                                                                                                                          \n","0                                                                        [Excellent game, worked really well!, Makes me think quickly...good brain exercise!]   \n","1                  [The Bible for Alexa is a great addition., Along with getting my daily dose from the scripture of the day, I can hear God's word anytime.]   \n","4       [I like it but I don't love it., I wish Alexa could just open my Verse of the day more easily , she seems to never understand ., I have to be so s...   \n","5                                                                               [Very useful skill and much needed., Setup is pretty easy and works reliably]   \n","8       [Takes a lil time to get everything set up but once its done, everything works like a charm., U can even back up your remotes from the app to open...   \n","...                                                                                                                                                       ...   \n","344800  [It was hard to keep the names of the characters straight., And the development of the characters certainly needed more development., But the acti...   \n","344802       [Another enjoyable read from Catherine Bybee., The hard part is putting it down!!, Great characters that make you want to follow their journey.]   \n","344803                                              [I was never quite sure who was going to die, Booker or Dani., I recommend the book for a rainy weekend.]   \n","344804                    [i really like the way the author leads you in multiple directions as to whom the \"client\" is., fun book to read during my breaks.]   \n","344807  [I've read three of Bobby Cole's books now, and this latest one didn't disappoint me., It was an action packed mystery thriller in a local souther...   \n","\n","        len  \n","cumlen       \n","0         1  \n","1         1  \n","4         3  \n","5         1  \n","8         3  \n","...     ...  \n","344800    2  \n","344802    2  \n","344803    1  \n","344804    1  \n","344807    3  \n","\n","[188702 rows x 2 columns]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["print(raw_data[\"splitted\"].apply(lambda x: len(x) - 1).sum())\n","raw_data[\"cumlen\"] = raw_data[\"splitted\"].apply(lambda x: len(x) - 1).cumsum() - 1\n","raw_data[\"len\"] = raw_data[\"splitted\"].apply(lambda x: len(x) - 1)\n","raw_data = raw_data.set_index(\"cumlen\")\n","\n","pd.options.display.max_colwidth = 150\n","raw_data"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["30b700830b22427bb9b6c9baf531754f","c52ad3a5e491402ca0450e98223c5f92","e7b62fcda1cd4ad89d6acb9894224c84","942817bb615f43b6bbef153607d1726c","43502962ed2443308cac3cab014fc884","271237b386024094b62c297e31ba1605","49c63bb85d87413eaa2e70a26b5c41c5","4b76e4af25d042ed9b1a84d7e6106e48","aab12219030f411da25047b71a28d569","4e5f3ad65ba2424c8916492d6b988ed1","13b6a56e9cfb491dbbeb0657b67d46ad","5155c1279a704fe787d16e47fddfa5a9","5633c4e2d47b47f5b26303dc06857e01","14a72691b6194e8c8d22922754b2a278","e1ba5f052f404c2cadf36e857f1b0ac4","359ce540ac3a4627926c0ba579b422be","2c968e30e00d4a25a3193d58d61df6d8","4466b35bcd9145b481faeb56e5044319","ad99ced523024b98a360345fa8f1af17","3dc0a2213d05478abefb1fb0a7181696","a810f3d48c6d48f19cdfcb327c6c8a70","7f9577e12bcc4bc88970a8bd44dac74e","6aaacde2a2844526b01af7ee0021951d","a60431b5009e4972990d8075a169eeab","3edf04ef76ec43ba87f721c180b82c6d","c101d8e6036d45fdb7eb14e698b0511e","f442b9ace69049aba9f77ed66d51f90c","cdb6ce95b17641e99b2c492be55f7761","6ebc57df86d64e96b99a49e3362c5ccc","ac79efaeb91b468d995c588eebc7eb19","0f8e95ac21c54b7595be6902f2e0d3c1","fec2a8f9f2e94c9d97e46bb070aa1a02","4371e711262f4b63956645b2516bd300"]},"executionInfo":{"elapsed":1576,"status":"ok","timestamp":1646888205700,"user":{"displayName":"Xiyan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcg993ydhhc_E_jLjU0Fbj_ESzMgkFXC4i6rHZEA=s64","userId":"16542303003688506111"},"user_tz":480},"id":"3f0v4iFqjiTC","outputId":"07f6601c-d514-4aa5-c683-c68da185e995"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"30b700830b22427bb9b6c9baf531754f","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/773k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5155c1279a704fe787d16e47fddfa5a9","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.32M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6aaacde2a2844526b01af7ee0021951d","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.17k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# initialize tokenizer for Dataset building\n","tokenizer = T5TokenizerFast.from_pretrained(\"t5-base\")"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1646888205701,"user":{"displayName":"Xiyan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcg993ydhhc_E_jLjU0Fbj_ESzMgkFXC4i6rHZEA=s64","userId":"16542303003688506111"},"user_tz":480},"id":"P0GQ7xwCjFwz"},"outputs":[],"source":["sent_length = 32\n","class AmazonDataset(Dataset):\n","    def __init__(self,data):\n","        self.data = data\n","        self.len = raw_data[\"splitted\"].apply(lambda x: len(x) - 1).sum()\n","\n","    def __len__(self):\n","        return self.len\n","\n","    def to_token(self,sentence):\n","        return tokenizer.encode(sentence, max_length=sent_length, truncation=True, padding=\"max_length\", return_tensors=\"pt\")[0]\n","    \n","    def get_pair(self, idx):\n","      iidx = idx\n","      while iidx not in raw_data.index:\n","        iidx += 1\n","      line = raw_data[\"splitted\"].loc[iidx]\n","      base = idx - iidx - 2\n","      return (line[base], line[base + 1])\n","\n","    def __getitem__(self,index):\n","        context, input = self.get_pair(index)\n","        return self.to_token(context), self.to_token(input)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":373,"status":"ok","timestamp":1646888206069,"user":{"displayName":"Xiyan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcg993ydhhc_E_jLjU0Fbj_ESzMgkFXC4i6rHZEA=s64","userId":"16542303003688506111"},"user_tz":480},"id":"3YoGVae3vYfj","outputId":"cd0437da-0717-403a-9a88-3ec448921755"},"outputs":[{"data":{"text/plain":["(tensor([11497,   467,     6,  1279,   310,   168,    55,     1,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0]),\n"," tensor([ 1796,     7,   140,   317,  1224,   233, 10452,  2241,  2510,    55,\n","             1,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0]))"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["AmazonDataset(raw_data)[0]"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1646888206069,"user":{"displayName":"Xiyan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcg993ydhhc_E_jLjU0Fbj_ESzMgkFXC4i6rHZEA=s64","userId":"16542303003688506111"},"user_tz":480},"id":"OscQSONTvgiN"},"outputs":[],"source":["batch_size = 32\n","\n","class AmazonDataModule(pl.LightningDataModule):\n","    def __init__(self):\n","        super().__init__()\n","        train_dataset, val_dataset = train_test_split(raw_data, test_size=0.2)\n","        self.train = AmazonDataset(train_dataset)\n","        self.test = AmazonDataset(val_dataset)\n","        self.val = AmazonDataset(val_dataset)\n","\n","    def train_dataloader(self):\n","        return DataLoader(self.train , batch_size = batch_size , shuffle = True, num_workers=4)\n","    def test_dataloader(self):\n","        return DataLoader(self.test , batch_size = batch_size , shuffle = False, num_workers=4)\n","    def val_dataloader(self):\n","        return DataLoader(self.val , batch_size = batch_size , shuffle = False, num_workers=4)"]},{"cell_type":"markdown","metadata":{"id":"clKMWEiGxbbs"},"source":["# Model Definition"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1646888206070,"user":{"displayName":"Xiyan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcg993ydhhc_E_jLjU0Fbj_ESzMgkFXC4i6rHZEA=s64","userId":"16542303003688506111"},"user_tz":480},"id":"CHGrrth8whTK"},"outputs":[],"source":["from transformers.models.t5.modeling_t5 import T5Stack, T5PreTrainedModel\n","from transformers.modeling_outputs import (BaseModelOutput,\n","    BaseModelOutputWithPastAndCrossAttentions,\n","    CausalLMOutputWithCrossAttentions,\n","    Seq2SeqLMOutput,\n","    Seq2SeqModelOutput,\n","    Seq2SeqQuestionAnsweringModelOutput,\n","    Seq2SeqSequenceClassifierOutput,)\n","from transformers.models.t5.configuration_t5 import T5Config\n","from transformers.utils.model_parallel_utils import get_device_map, assert_device_map\n","import warnings\n","import copy\n","\n","__HEAD_MASK_WARNING_MSG = \"\"\"\n","The input argument `head_mask` was split into two arguments `head_mask` and `decoder_head_mask`. Currently,\n","`decoder_head_mask` is set to copy `head_mask`, but this feature is deprecated and will be removed in future versions.\n","If you do not want to use any `decoder_head_mask` now, please set `decoder_head_mask = torch.ones(num_layers,\n","num_heads)`.\n","\"\"\""]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":478,"status":"ok","timestamp":1646888206543,"user":{"displayName":"Xiyan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcg993ydhhc_E_jLjU0Fbj_ESzMgkFXC4i6rHZEA=s64","userId":"16542303003688506111"},"user_tz":480},"id":"nuLN-pOSx8er"},"outputs":[],"source":["lambda_factor = 1\n","class T5ForConditionalGenerationWithExtractor(T5PreTrainedModel):\n","    _keys_to_ignore_on_load_missing = [\n","        r\"encoder\\.embed_tokens\\.weight\",\n","        r\"decoder\\.embed_tokens\\.weight\",\n","        r\"lm_head\\.weight\",\n","    ]\n","    _keys_to_ignore_on_load_unexpected = [\n","        r\"decoder\\.block\\.0\\.layer\\.1\\.EncDecAttention\\.relative_attention_bias\\.weight\",\n","    ]\n","\n","    def __init__(self, config):\n","        super().__init__(config)\n","        self.model_dim = config.d_model\n","\n","        self.shared = nn.Embedding(config.vocab_size, config.d_model)\n","\n","        encoder_config = copy.deepcopy(config)\n","        encoder_config.is_decoder = False\n","        encoder_config.use_cache = False\n","        encoder_config.is_encoder_decoder = False\n","        self.encoder = T5Stack(encoder_config, self.shared)\n","\n","        extractor_config = copy.deepcopy(config)\n","        extractor_config.is_decoder = False\n","        extractor_config.use_cache = False\n","        extractor_config.is_encoder_decoder = False\n","        self.extractor = T5Stack(extractor_config, self.shared)\n","\n","        decoder_config = copy.deepcopy(config)\n","        decoder_config.is_decoder = True\n","        decoder_config.is_encoder_decoder = False\n","        decoder_config.num_layers = config.num_decoder_layers\n","        self.decoder = T5Stack(decoder_config, self.shared)\n","\n","        self.lm_head = nn.Linear(config.d_model, config.vocab_size, bias=False)\n","\n","        # Initialize weights and apply final processing\n","        self.post_init()\n","\n","        # Model parallel\n","        self.model_parallel = False\n","        self.device_map = None\n","\n","    def parallelize(self, device_map=None):\n","        self.device_map = (\n","            get_device_map(len(self.encoder.block), range(torch.cuda.device_count()))\n","            if device_map is None\n","            else device_map\n","        )\n","        assert_device_map(self.device_map, len(self.encoder.block))\n","        self.encoder.parallelize(self.device_map)\n","        self.decoder.parallelize(self.device_map)\n","        self.extractor.parallelize(self.device_map)\n","        self.lm_head = self.lm_head.to(self.decoder.first_device)\n","        self.model_parallel = True\n","\n","    def deparallelize(self):\n","        self.encoder.deparallelize()\n","        self.extractor.deparallelize()\n","        self.decoder.deparallelize()\n","        self.encoder = self.encoder.to(\"cpu\")\n","        self.extractor = self.extractor.to(\"cpu\")\n","        self.decoder = self.decoder.to(\"cpu\")\n","        self.lm_head = self.lm_head.to(\"cpu\")\n","        self.model_parallel = False\n","        self.device_map = None\n","        torch.cuda.empty_cache()\n","\n","    def get_input_embeddings(self):\n","        return self.shared\n","\n","    def set_input_embeddings(self, new_embeddings):\n","        self.shared = new_embeddings\n","        self.encoder.set_input_embeddings(new_embeddings)\n","        self.extractor.set_input_embeddings(new_embeddings)\n","        self.decoder.set_input_embeddings(new_embeddings)\n","\n","    def set_output_embeddings(self, new_embeddings):\n","        self.lm_head = new_embeddings\n","\n","    def get_output_embeddings(self):\n","        return self.lm_head\n","\n","    def get_encoder(self):\n","        return self.encoder\n","    \n","    def get_extractor(self):\n","        return self.extractor\n","\n","    def get_decoder(self):\n","        return self.decoder\n","\n","    def get_extractor_output(self,\n","        input_ids=None,\n","        use_cache_context_ids=None, # use cache is simply to a trick to use the generator mixin\n","        use_cache_target_examplars_ids=None,\n","        use_cache_origin_examplars_ids=None,\n","        attention_mask=None,\n","        decoder_input_ids=None,\n","        decoder_attention_mask=None,\n","        head_mask=None,\n","        decoder_head_mask=None,\n","        cross_attn_head_mask=None,\n","        encoder_outputs=None,\n","        extractor_outputs=None,\n","        past_key_values=None,\n","        inputs_embeds=None,\n","        context_embeds=None,\n","        decoder_inputs_embeds=None,\n","        labels=None,\n","        use_cache=None,\n","        output_attentions=None,\n","        output_hidden_states=None,\n","        return_dict=None,):\n","      extractor_hidden = None\n","      if use_cache_context_ids is None:\n","        target_styles = ()\n","        for target_ids in use_cache_target_examplars_ids:\n","          extractor_hidden = self.extractor(\n","              input_ids=target_ids,\n","              attention_mask=attention_mask,\n","              inputs_embeds=context_embeds,\n","              head_mask=head_mask,\n","              output_attentions=output_attentions,\n","              output_hidden_states=output_hidden_states,\n","              return_dict=return_dict,\n","          )[0]\n","          target_styles += (extractor_hidden,)\n","\n","        original_styles = ()\n","        for origin_ids in use_cache_origin_examplars_ids:\n","          extractor_hidden = self.extractor(\n","              input_ids=origin_ids,\n","              attention_mask=attention_mask,\n","              inputs_embeds=context_embeds,\n","              head_mask=head_mask,\n","              output_attentions=output_attentions,\n","              output_hidden_states=output_hidden_states,\n","              return_dict=return_dict,\n","          )[0]\n","          original_styles += (extractor_hidden,)\n","          \n","        input_style = self.extractor(\n","              input_ids=input_ids,\n","              attention_mask=attention_mask,\n","              inputs_embeds=context_embeds,\n","              head_mask=head_mask,\n","              output_attentions=output_attentions,\n","              output_hidden_states=output_hidden_states,\n","              return_dict=return_dict,\n","          )[0]\n","        extractor_hidden = lambda_factor * (torch.mean(torch.vstack(target_styles), 0) - (torch.mean(torch.vstack(original_styles), 0))) + input_style\n","      \n","      else:\n","        if extractor_outputs is None:\n","            extractor_outputs = self.extractor(\n","                input_ids=use_cache_context_ids,\n","                attention_mask=attention_mask,\n","                inputs_embeds=context_embeds,\n","                head_mask=head_mask,\n","                output_attentions=output_attentions,\n","                output_hidden_states=output_hidden_states,\n","                return_dict=return_dict,\n","            )\n","        elif return_dict and not isinstance(encoder_outputs, BaseModelOutput):\n","            extractor_outputs = BaseModelOutput(\n","                last_hidden_state=extractor_outputs[0],\n","                hidden_states=extractor_outputs[1] if len(extractor_outputs) > 1 else None,\n","                attentions=extractor_outputs[2] if len(extractor_outputs) > 2 else None,)\n","        extractor_hidden = extractor_outputs[0]\n","      return extractor_hidden\n","        \n","    def forward(\n","        self,\n","        input_ids=None,\n","        attention_mask=None,\n","        decoder_input_ids=None,\n","        decoder_attention_mask=None,\n","        head_mask=None,\n","        decoder_head_mask=None,\n","        cross_attn_head_mask=None,\n","        encoder_outputs=None,\n","        use_cache_extractor_outputs=None,\n","        past_key_values=None,\n","        inputs_embeds=None,\n","        context_embeds=None,\n","        decoder_inputs_embeds=None,\n","        labels=None,\n","        use_cache=None,\n","        output_attentions=None,\n","        output_hidden_states=None,\n","        return_dict=None,\n","    ):\n","        r\"\"\"\n","        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n","            Labels for computing the sequence classification/regression loss. Indices should be in `[-100, 0, ...,\n","            config.vocab_size - 1]`. All labels set to `-100` are ignored (masked), the loss is only computed for\n","            labels in `[0, ..., config.vocab_size]`\n","        Returns:\n","        Examples:\n","        ```python\n","        >>> from transformers import T5Tokenizer, T5ForConditionalGeneration\n","        >>> tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n","        >>> model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n","        >>> # training\n","        >>> input_ids = tokenizer(\"The <extra_id_0> walks in <extra_id_1> park\", return_tensors=\"pt\").input_ids\n","        >>> labels = tokenizer(\"<extra_id_0> cute dog <extra_id_1> the <extra_id_2>\", return_tensors=\"pt\").input_ids\n","        >>> outputs = model(input_ids=input_ids, labels=labels)\n","        >>> loss = outputs.loss\n","        >>> logits = outputs.logits\n","        >>> # inference\n","        >>> input_ids = tokenizer(\n","        ...     \"summarize: studies have shown that owning a dog is good for you\", return_tensors=\"pt\"\n","        >>> ).input_ids  # Batch size 1\n","        >>> outputs = model.generate(input_ids)\n","        >>> print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n","        >>> # studies have shown that owning a dog is good for you.\n","        ```\"\"\"\n","        use_cache = use_cache if use_cache is not None else self.config.use_cache\n","        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n","\n","        # FutureWarning: head_mask was separated into two input args - head_mask, decoder_head_mask\n","        if head_mask is not None and decoder_head_mask is None:\n","            if self.config.num_layers == self.config.num_decoder_layers:\n","                warnings.warn(__HEAD_MASK_WARNING_MSG, FutureWarning)\n","                decoder_head_mask = head_mask\n","\n","        # Encode if needed (training, first prediction pass)\n","        if encoder_outputs is None:\n","            # Convert encoder inputs in embeddings if needed\n","            encoder_outputs = self.encoder(\n","                input_ids=input_ids,\n","                attention_mask=attention_mask,\n","                inputs_embeds=inputs_embeds,\n","                head_mask=head_mask,\n","                output_attentions=output_attentions,\n","                output_hidden_states=output_hidden_states,\n","                return_dict=return_dict,\n","            )\n","        elif return_dict and not isinstance(encoder_outputs, BaseModelOutput):\n","            encoder_outputs = BaseModelOutput(\n","                last_hidden_state=encoder_outputs[0],\n","                hidden_states=encoder_outputs[1] if len(encoder_outputs) > 1 else None,\n","                attentions=encoder_outputs[2] if len(encoder_outputs) > 2 else None,\n","            )\n","\n","        hidden_states = encoder_outputs[0] + use_cache_extractor_outputs\n","\n","        if self.model_parallel:\n","            torch.cuda.set_device(self.decoder.first_device)\n","\n","        if labels is not None and decoder_input_ids is None and decoder_inputs_embeds is None:\n","            # get decoder inputs from shifting lm labels to the right\n","            decoder_input_ids = self._shift_right(labels)\n","\n","        # Set device for model parallelism\n","        if self.model_parallel:\n","            torch.cuda.set_device(self.decoder.first_device)\n","            hidden_states = hidden_states.to(self.decoder.first_device)\n","            if decoder_input_ids is not None:\n","                decoder_input_ids = decoder_input_ids.to(self.decoder.first_device)\n","            if attention_mask is not None:\n","                attention_mask = attention_mask.to(self.decoder.first_device)\n","            if decoder_attention_mask is not None:\n","                decoder_attention_mask = decoder_attention_mask.to(self.decoder.first_device)\n","\n","        # Decode\n","        decoder_outputs = self.decoder(\n","            input_ids=decoder_input_ids,\n","            attention_mask=decoder_attention_mask,\n","            inputs_embeds=decoder_inputs_embeds,\n","            past_key_values=past_key_values,\n","            encoder_hidden_states=hidden_states,\n","            encoder_attention_mask=attention_mask,\n","            head_mask=decoder_head_mask,\n","            cross_attn_head_mask=cross_attn_head_mask,\n","            use_cache=use_cache,\n","            output_attentions=output_attentions,\n","            output_hidden_states=output_hidden_states,\n","            return_dict=return_dict,\n","        )\n","\n","        sequence_output = decoder_outputs[0]\n","\n","        # Set device for model parallelism\n","        if self.model_parallel:\n","            torch.cuda.set_device(self.encoder.first_device)\n","            self.lm_head = self.lm_head.to(self.encoder.first_device)\n","            sequence_output = sequence_output.to(self.lm_head.weight.device)\n","\n","        if self.config.tie_word_embeddings:\n","            # Rescale output before projecting on vocab\n","            # See https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/transformer/transformer.py#L586\n","            sequence_output = sequence_output * (self.model_dim**-0.5)\n","\n","        lm_logits = self.lm_head(sequence_output)\n","\n","        loss = None\n","        if labels is not None:\n","            loss_fct = torch.nn.CrossEntropyLoss(ignore_index=-100)\n","            loss = loss_fct(lm_logits.view(-1, lm_logits.size(-1)), labels.view(-1))\n","            # TODO(thom): Add z_loss https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/layers.py#L666\n","\n","        if not return_dict:\n","            output = (lm_logits,) + decoder_outputs[1:] + encoder_outputs\n","            return ((loss,) + output) if loss is not None else output\n","\n","        return Seq2SeqLMOutput(\n","            loss=loss,\n","            logits=lm_logits,\n","            past_key_values=decoder_outputs.past_key_values,\n","            decoder_hidden_states=decoder_outputs.hidden_states,\n","            decoder_attentions=decoder_outputs.attentions,\n","            cross_attentions=decoder_outputs.cross_attentions,\n","            encoder_last_hidden_state=encoder_outputs.last_hidden_state,\n","            encoder_hidden_states=encoder_outputs.hidden_states,\n","            encoder_attentions=encoder_outputs.attentions,\n","        )\n","\n","    def prepare_inputs_for_generation(\n","        self,\n","        input_ids,\n","        use_cache_extractor_outputs=None,\n","        past=None,\n","        attention_mask=None,\n","        head_mask=None,\n","        decoder_head_mask=None,\n","        cross_attn_head_mask=None,\n","        use_cache=None,\n","        encoder_outputs=None,\n","        **kwargs\n","    ):\n","\n","        # cut decoder_input_ids if past is used\n","        if past is not None:\n","            input_ids = input_ids[:, -1:]\n","\n","        return {\n","            # \"input_ids\": input_ids,\n","            # \"use_cache_context_ids\": use_cache_context_ids,\n","            # \"use_cache_target_examplars_ids\": use_cache_target_examplars_ids,\n","            # \"use_cache_origin_examplars_ids\": use_cache_origin_examplars_ids,\n","            \"decoder_input_ids\": input_ids,\n","            \"past_key_values\": past,\n","            \"encoder_outputs\": encoder_outputs,\n","            \"use_cache_extractor_outputs\": use_cache_extractor_outputs,\n","            \"attention_mask\": attention_mask,\n","            \"head_mask\": head_mask,\n","            \"decoder_head_mask\": decoder_head_mask,\n","            \"cross_attn_head_mask\": cross_attn_head_mask,\n","            \"use_cache\": use_cache,\n","        }\n","\n","    def prepare_decoder_input_ids_from_labels(self, labels: torch.Tensor):\n","        return self._shift_right(labels)\n","\n","    def _reorder_cache(self, past, beam_idx):\n","        # if decoder past is not included in output\n","        # speedy decoding is disabled and no need to reorder\n","        if past is None:\n","            warnings.warning(\"You might want to consider setting `use_cache=True` to speed up decoding\")\n","            return past\n","\n","        reordered_decoder_past = ()\n","        for layer_past_states in past:\n","            # get the correct batch idx from layer past batch dim\n","            # batch dim of `past` is at 2nd position\n","            reordered_layer_past_states = ()\n","            for layer_past_state in layer_past_states:\n","                # need to set correct `past` for each of the four key / value states\n","                reordered_layer_past_states = reordered_layer_past_states + (\n","                    layer_past_state.index_select(0, beam_idx.to(layer_past_state.device)),\n","                )\n","\n","            assert reordered_layer_past_states[0].shape == layer_past_states[0].shape\n","            assert len(reordered_layer_past_states) == len(layer_past_states)\n","\n","            reordered_decoder_past = reordered_decoder_past + (reordered_layer_past_states,)\n","        return reordered_decoder_past\n"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104,"referenced_widgets":["091a52c8cf2347b4a32b28f0caade351","854140efaafa42e483b7892f9afac023","3068cd5617c944e3aac4a9743daeac44","5e7cd241a7da4e279a2f824575352000","141d9220abcd427dbf67af00e1081c0f","573ec4b28bc54604aa187b824d9e84be","83b81b4255cd4fbcab46b2cd5aa5fe35","8f09e9fdac4c4258816911943a9279fd","fd37662034814ed1a0bf4297f18fa444","531f7016aefd421780aaf594b72f55dd","a91709688baf4a0a8a9f853dc41a2e8d"]},"executionInfo":{"elapsed":29018,"status":"ok","timestamp":1646888235558,"user":{"displayName":"Xiyan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcg993ydhhc_E_jLjU0Fbj_ESzMgkFXC4i6rHZEA=s64","userId":"16542303003688506111"},"user_tz":480},"id":"anL1dLwzyqsO","outputId":"3846e36d-9dd0-41cc-df0d-312ffbf33d47"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"091a52c8cf2347b4a32b28f0caade351","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/850M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of T5ForConditionalGenerationWithExtractor were not initialized from the model checkpoint at t5-base and are newly initialized: ['extractor.block.9.layer.0.layer_norm.weight', 'extractor.block.2.layer.1.DenseReluDense.wo.weight', 'extractor.block.7.layer.1.DenseReluDense.wo.weight', 'extractor.block.0.layer.1.DenseReluDense.wi.weight', 'extractor.block.5.layer.1.DenseReluDense.wo.weight', 'extractor.block.2.layer.1.layer_norm.weight', 'extractor.block.6.layer.0.SelfAttention.q.weight', 'extractor.final_layer_norm.weight', 'extractor.block.9.layer.0.SelfAttention.o.weight', 'extractor.block.11.layer.1.DenseReluDense.wo.weight', 'extractor.block.1.layer.1.layer_norm.weight', 'extractor.block.2.layer.1.DenseReluDense.wi.weight', 'extractor.block.3.layer.0.layer_norm.weight', 'extractor.block.7.layer.0.SelfAttention.v.weight', 'extractor.block.8.layer.1.DenseReluDense.wo.weight', 'extractor.block.9.layer.0.SelfAttention.k.weight', 'extractor.block.10.layer.0.SelfAttention.v.weight', 'extractor.block.10.layer.1.DenseReluDense.wi.weight', 'extractor.block.10.layer.0.layer_norm.weight', 'extractor.block.1.layer.1.DenseReluDense.wi.weight', 'extractor.block.9.layer.0.SelfAttention.v.weight', 'extractor.block.0.layer.0.SelfAttention.o.weight', 'extractor.block.0.layer.0.SelfAttention.q.weight', 'extractor.block.3.layer.1.layer_norm.weight', 'extractor.block.11.layer.0.layer_norm.weight', 'extractor.block.11.layer.1.DenseReluDense.wi.weight', 'extractor.block.7.layer.1.DenseReluDense.wi.weight', 'extractor.block.7.layer.0.SelfAttention.o.weight', 'extractor.block.11.layer.0.SelfAttention.q.weight', 'extractor.block.10.layer.0.SelfAttention.q.weight', 'extractor.block.8.layer.1.DenseReluDense.wi.weight', 'extractor.block.10.layer.1.DenseReluDense.wo.weight', 'extractor.block.0.layer.0.SelfAttention.k.weight', 'extractor.block.0.layer.1.DenseReluDense.wo.weight', 'extractor.block.11.layer.0.SelfAttention.k.weight', 'extractor.block.10.layer.1.layer_norm.weight', 'extractor.block.5.layer.1.layer_norm.weight', 'extractor.block.8.layer.0.SelfAttention.o.weight', 'extractor.block.2.layer.0.layer_norm.weight', 'extractor.block.10.layer.0.SelfAttention.k.weight', 'extractor.block.3.layer.0.SelfAttention.k.weight', 'extractor.block.5.layer.0.layer_norm.weight', 'extractor.block.8.layer.0.layer_norm.weight', 'extractor.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'extractor.block.9.layer.1.DenseReluDense.wo.weight', 'extractor.block.4.layer.0.SelfAttention.k.weight', 'extractor.block.5.layer.0.SelfAttention.o.weight', 'extractor.block.9.layer.1.DenseReluDense.wi.weight', 'extractor.block.4.layer.0.layer_norm.weight', 'extractor.block.4.layer.1.DenseReluDense.wi.weight', 'extractor.block.3.layer.0.SelfAttention.q.weight', 'extractor.block.11.layer.0.SelfAttention.o.weight', 'extractor.block.1.layer.0.SelfAttention.o.weight', 'extractor.block.6.layer.0.SelfAttention.o.weight', 'extractor.block.9.layer.1.layer_norm.weight', 'extractor.block.3.layer.1.DenseReluDense.wi.weight', 'extractor.block.10.layer.0.SelfAttention.o.weight', 'extractor.block.11.layer.0.SelfAttention.v.weight', 'extractor.block.5.layer.0.SelfAttention.v.weight', 'extractor.block.4.layer.1.DenseReluDense.wo.weight', 'extractor.block.4.layer.0.SelfAttention.o.weight', 'extractor.block.0.layer.1.layer_norm.weight', 'extractor.block.8.layer.0.SelfAttention.k.weight', 'extractor.block.2.layer.0.SelfAttention.v.weight', 'extractor.block.6.layer.1.DenseReluDense.wi.weight', 'extractor.block.3.layer.0.SelfAttention.o.weight', 'extractor.block.1.layer.0.SelfAttention.k.weight', 'extractor.block.2.layer.0.SelfAttention.q.weight', 'extractor.block.3.layer.0.SelfAttention.v.weight', 'extractor.block.3.layer.1.DenseReluDense.wo.weight', 'extractor.block.1.layer.0.SelfAttention.q.weight', 'extractor.block.8.layer.0.SelfAttention.q.weight', 'extractor.block.6.layer.0.SelfAttention.k.weight', 'extractor.block.2.layer.0.SelfAttention.k.weight', 'extractor.block.6.layer.1.DenseReluDense.wo.weight', 'extractor.block.7.layer.0.SelfAttention.q.weight', 'extractor.block.5.layer.0.SelfAttention.q.weight', 'extractor.block.5.layer.1.DenseReluDense.wi.weight', 'extractor.block.8.layer.1.layer_norm.weight', 'extractor.block.4.layer.0.SelfAttention.q.weight', 'extractor.embed_tokens.weight', 'extractor.block.1.layer.0.layer_norm.weight', 'extractor.block.6.layer.1.layer_norm.weight', 'extractor.block.5.layer.0.SelfAttention.k.weight', 'extractor.block.1.layer.1.DenseReluDense.wo.weight', 'extractor.block.8.layer.0.SelfAttention.v.weight', 'extractor.block.4.layer.1.layer_norm.weight', 'extractor.block.0.layer.0.SelfAttention.v.weight', 'extractor.block.4.layer.0.SelfAttention.v.weight', 'extractor.block.6.layer.0.layer_norm.weight', 'extractor.block.0.layer.0.layer_norm.weight', 'extractor.block.11.layer.1.layer_norm.weight', 'extractor.block.2.layer.0.SelfAttention.o.weight', 'extractor.block.7.layer.0.layer_norm.weight', 'extractor.block.1.layer.0.SelfAttention.v.weight', 'extractor.block.7.layer.0.SelfAttention.k.weight', 'extractor.block.9.layer.0.SelfAttention.q.weight', 'extractor.block.7.layer.1.layer_norm.weight', 'extractor.block.6.layer.0.SelfAttention.v.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["model = T5ForConditionalGenerationWithExtractor.from_pretrained(\"t5-base\")\n","# model = T5ForConditionalGenerationWithExtractor.from_pretrained(\"check\")"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1646888235558,"user":{"displayName":"Xiyan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcg993ydhhc_E_jLjU0Fbj_ESzMgkFXC4i6rHZEA=s64","userId":"16542303003688506111"},"user_tz":480},"id":"TcyEfMoMvqxn"},"outputs":[],"source":["model.extractor = copy.deepcopy(model.encoder)\n","model.extractor.is_extractor = True"]},{"cell_type":"markdown","metadata":{"id":"kE-vg2r7LhZv"},"source":["# Utils"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1646888235558,"user":{"displayName":"Xiyan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcg993ydhhc_E_jLjU0Fbj_ESzMgkFXC4i6rHZEA=s64","userId":"16542303003688506111"},"user_tz":480},"id":"1EqtVMAm0wqz"},"outputs":[],"source":["def peek_weights():\n","  for i, k in model.named_parameters():\n","    if \"block.2.layer.0.SelfAttention.k.weight\" in i:\n","      print(i)\n","      print(k)"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1646888235560,"user":{"displayName":"Xiyan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcg993ydhhc_E_jLjU0Fbj_ESzMgkFXC4i6rHZEA=s64","userId":"16542303003688506111"},"user_tz":480},"id":"cNTjgurYKG2w"},"outputs":[],"source":["def tokenize(input):\n","  return tokenizer(input, max_length=sent_length, truncation=True, padding=\"max_length\", return_tensors=\"pt\").input_ids.cuda()"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1646888235560,"user":{"displayName":"Xiyan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcg993ydhhc_E_jLjU0Fbj_ESzMgkFXC4i6rHZEA=s64","userId":"16542303003688506111"},"user_tz":480},"id":"NVRdRzb62jzq"},"outputs":[],"source":["def peek_output(input, context):\n","  print(\"input:\", input)\n","  print(\"context:\", context)\n","  input_ids = tokenize(input)\n","  context_ids = tokenize(context)\n","  extractor_output = model.net.get_extractor_output(use_cache_context_ids=context_ids)\n","  print(extractor_output)\n","  outputs = model.net.generate(input_ids=input_ids, use_cache_extractor_outputs=extractor_output, no_repeat_ngram_size=2)\n","  print(outputs)\n","  return tokenizer.decode(outputs[0], skip_special_tokens=True)"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":211,"status":"ok","timestamp":1646888235765,"user":{"displayName":"Xiyan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcg993ydhhc_E_jLjU0Fbj_ESzMgkFXC4i6rHZEA=s64","userId":"16542303003688506111"},"user_tz":480},"id":"N5NlTZFmJ99D"},"outputs":[],"source":["def peek_transfer_output(input, target_examplars, origin_examplars):\n","  targets = ()\n","  for sent in target_examplars:\n","    targets += (tokenize(sent),)\n","  origins = ()\n","  for sent in origin_examplars:\n","    origins += (tokenize(sent),)\n","  input_ids = tokenize(input)\n","  extractor_output = model.net.get_extractor_output(input_ids=input_ids, use_cache_origin_examplars_ids=origins, use_cache_target_examplars_ids=targets)\n","  print(extractor_output)\n","  outputs = model.net.generate(input_ids=input_ids, use_cache_extractor_outputs=extractor_output, no_repeat_ngram_size=2)\n","  return tokenizer.decode(outputs[0], skip_special_tokens=True)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1646888235765,"user":{"displayName":"Xiyan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcg993ydhhc_E_jLjU0Fbj_ESzMgkFXC4i6rHZEA=s64","userId":"16542303003688506111"},"user_tz":480},"id":"YwgrVjx2HjYz","outputId":"e30914c1-e7af-4696-da61-a23ad02802fb"},"outputs":[{"data":{"text/plain":["True"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["np.random.choice([False, True])"]},{"cell_type":"markdown","metadata":{"id":"iNW5wkBMGEE-"},"source":["# Module and Training"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":9103,"status":"ok","timestamp":1646888244867,"user":{"displayName":"Xiyan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcg993ydhhc_E_jLjU0Fbj_ESzMgkFXC4i6rHZEA=s64","userId":"16542303003688506111"},"user_tz":480},"id":"1pt2uXA9LoZn"},"outputs":[],"source":["sent_ex = torch.tensor([[   27,   131,  1663,    79,   133,    59,    43,   974,     8, 11769,\n","          4546,    49,     5,     1,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0],\n","        [  216,   237,  5495,  1361,    95,    16,     3,     9,  1996,   300,\n","            34,     5,     1,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0],\n","        [   27,   183, 13049,    82, 17442,     3,     9,  3591,  1088,    12,\n","            84,  2586,  2281,    56,    36,     8,  3800,     5,     1,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0],\n","        [   27,  2944,    48,     3,  4894,    12,  1115,     3,     9,   314,\n","           226,   591, 16739,   682,     5,     1,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0],\n","        [ 4242,  2437,    11,   614,    12,   888,   300,    68,  1355,  5366,\n","            55,     1,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0],\n","        [  299,    27,    47,   652,     3,     9,   385,  7718,    13,     8,\n","         24839,  4496,  5891,     5,     1,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0],\n","        [  100,  4035, 15133,   930,   248,    30,    82,  1367,    49,     5,\n","             5,     1,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0],\n","        [  555,    13,     8,   200,  3370,  1335,    27,   664,   608,     5,\n","             1,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0],\n","        [   27,  1800,     8,   733,   906,     3,     9,   385,    72,  1848,\n","           606,     6,    68,     8,  1006,  4974,  5689,    39,  1388,     5,\n","             1,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0],\n","        [   27,  2112, 13771, 16802,    78,     8,  6519,   744,    31,    17,\n","         13965,   140,    68,   406,   135,     8, 17956,     7,    33, 10875,\n","             5,     1,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0],\n","        [   37, 10485,    11,  6922,    19,   248,    68,  1879,     8,  1974,\n","            19,   131,   773,    13, 15170,     5,     1,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0],\n","        [   37,  2507,   505,    19,     3,     9,   385,    72,  2881,   145,\n","             8,   119,  4935,  3592,    68,    70,   168,  1494,     8,   594,\n","             5,     1,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0],\n","        [28291,    79,    31,    60,   131,    21, 11649,   383,     8,  6799,\n","             5,     1,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0],\n","        [ 1853,  5705,  9664,  4386,  4486,  4083, 28027,   427, 17098,   272,\n","          5767,  5946, 11973,     3, 14750, 19056,  6223, 28969,  3001, 21490,\n","          1853,     3, 13729,   301, 19114,  7212, 21337,  8043,   445, 19114,\n","             3,     1],\n","        [  216,    65,     3,     9,  1627,  1418,    12,    36,  1835,    11,\n","         15391,    75,     6,    28,   418,    31,     7,    13,  2093,  2886,\n","          3358,     5,     1,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0],\n","        [ 8302,   608,     6,  4324,  3801,    15,  1329,     3,    99,  1066,\n","         24839,     5,     1,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0]], device='cuda:0')\n","\n","def drop_noise(sent, drop_rate=0.2):\n","  for i in range(int(((sent > 1).sum() * drop_rate))):\n","    randIdx = np.random.choice(np.where((sent > 1).cpu())[0])\n","    sent = torch.concat((sent[:randIdx], sent[randIdx + 1:]))\n","  return sent\n","\n","\n","special_tokens_set = set(tokenizer.all_special_ids)\n","\n","def rand_token():\n","  t = np.random.randint(tokenizer.vocab_size)\n","  if t in special_tokens_set:\n","    return rand_token()\n","  return t\n","\n","\n","def add_noise(sent, drop_rate=0.4):\n","  for i in range(int(((sent > 1).sum() * drop_rate))):\n","    randIdx = np.random.choice(np.where((sent > 1).cpu())[0])\n","    sent = torch.concat((sent[:randIdx], torch.tensor([rand_token()]).cuda(), sent[randIdx:]))\n","  return sent\n","\n","def pad_sent(sent, target=sent_length):\n","  if sent.shape[0] > target:\n","    return sent[:target]\n","  return torch.concat((sent, torch.zeros(target - sent.shape[0], dtype=torch.long).cuda()))\n","\n","# def drop_noise_(sent, drop_rate=0.4):\n","#   for i in range(int(sent.shape[0] * drop_rate)):\n","#     randIdx = np.random.randint(sent.shape[0])\n","#     sent = torch.concat((sent[:randIdx], sent[randIdx + 1:]))\n","#   return sent\n","\n","def apply_noise(sents):\n","  res = ()\n","  for i, sent in enumerate(sents):\n","    sent = drop_noise(sent)\n","    sent = add_noise(sent)\n","    sent = pad_sent(sent)\n","    res += (sent,)\n","  return torch.vstack(res)\n"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1646888244868,"user":{"displayName":"Xiyan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcg993ydhhc_E_jLjU0Fbj_ESzMgkFXC4i6rHZEA=s64","userId":"16542303003688506111"},"user_tz":480},"id":"fF8g_Sc_wTBK"},"outputs":[],"source":["class TextSettrModel(LightningModule):\n","    def __init__(self):\n","      super().__init__()\n","      self.net = T5ForConditionalGenerationWithExtractor.from_pretrained(\"t5-base\")\n","      self.net.extractor = copy.deepcopy(self.net.encoder)\n","    \n","    def training_step(self, batch, batch_idx):\n","      context_ids, input_ids = batch[0], batch[1]\n","      noisy_input_ids = apply_noise(input_ids)\n","      if np.random.choice([False, False, True]):\n","        # Noisy back translation\n","        noisy_input_ids = self.net.generate(input_ids=noisy_input_ids, use_cache_extractor_outputs=0, do_sample=True, max_length=sent_length, min_length=sent_length)\n","      extractor_output = self.net.get_extractor_output(use_cache_context_ids=context_ids)\n","      return self.net(input_ids=noisy_input_ids, labels = input_ids, use_cache_extractor_outputs=extractor_output).loss\n","\n","    def validation_step(self, batch, batch_idx):\n","      context_ids, input_ids = batch[0], batch[1]\n","      noisy_input_ids = apply_noise(input_ids)\n","      if np.random.choice([False, True]):\n","        # Noisy back translation\n","        noisy_input_ids = self.net.generate(input_ids=noisy_input_ids, use_cache_extractor_outputs=0, do_sample=True, max_length=sent_length, min_length=sent_length)\n","      extractor_output = self.net.get_extractor_output(use_cache_context_ids=context_ids)\n","      self.log(\"val_loss\", self.net(input_ids=noisy_input_ids, labels = input_ids, use_cache_extractor_outputs=extractor_output).loss)\n","\n","    def configure_optimizers(self):\n","        return torch.optim.AdamW(self.net.parameters(), 1e-3)"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":364,"referenced_widgets":["d0f16f1fffe547358894479697e6f3e5","a6f1fad5e5ca4f11993ee5a693168a71","5c795c4c3aba4e6ba45d9e713ec0a4bd","60e23a09cf9e4dd48ef2ba97ee07793d","024e775bf4b54a969537b3a8b7fa4254","46a79c6e290842afaf2e82ef09ebbc14","c7aa58d9650740aaabb35426796c0e12","c3e243fa2fa9457aa431e14b312617ec","4b7300c59877494ea7433181920f6102","b916434bb5fd47de823893a7afa565d8","160b824ba95e4781abd186745f276dff","73f09069949e46cd9fe8cf354c961bc7","98a7180bf665423485a89e392f0fa97a","bd808ebcf0434eafb9cac74610d9a0b1","4d2f9bdc3e414e10961415c5bc665728","49f17e67c08d4a2db23f75a66e9451b9","e5aebbc19cbf43d593089426f3f1a94c","4551bee7755048c5b319ba2d3b91af66","bb4fdab530e645aa9756417d65320238","d1af4f7e7dcf4bd69d5e89526b783c83","960b230b6d0e40368093c0a7406481f4","04d7d09c85d54ed6a705e1d80ebe0b7c"]},"executionInfo":{"elapsed":11537,"status":"ok","timestamp":1646888256400,"user":{"displayName":"Xiyan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcg993ydhhc_E_jLjU0Fbj_ESzMgkFXC4i6rHZEA=s64","userId":"16542303003688506111"},"user_tz":480},"id":"4s0068ofFgGA","outputId":"10f9f404-ca66-4e1c-c73a-061f2ee8919d"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of T5ForConditionalGenerationWithExtractor were not initialized from the model checkpoint at t5-base and are newly initialized: ['extractor.block.9.layer.0.layer_norm.weight', 'extractor.block.2.layer.1.DenseReluDense.wo.weight', 'extractor.block.7.layer.1.DenseReluDense.wo.weight', 'extractor.block.0.layer.1.DenseReluDense.wi.weight', 'extractor.block.5.layer.1.DenseReluDense.wo.weight', 'extractor.block.2.layer.1.layer_norm.weight', 'extractor.block.6.layer.0.SelfAttention.q.weight', 'extractor.final_layer_norm.weight', 'extractor.block.9.layer.0.SelfAttention.o.weight', 'extractor.block.11.layer.1.DenseReluDense.wo.weight', 'extractor.block.1.layer.1.layer_norm.weight', 'extractor.block.2.layer.1.DenseReluDense.wi.weight', 'extractor.block.3.layer.0.layer_norm.weight', 'extractor.block.7.layer.0.SelfAttention.v.weight', 'extractor.block.8.layer.1.DenseReluDense.wo.weight', 'extractor.block.9.layer.0.SelfAttention.k.weight', 'extractor.block.10.layer.0.SelfAttention.v.weight', 'extractor.block.10.layer.1.DenseReluDense.wi.weight', 'extractor.block.10.layer.0.layer_norm.weight', 'extractor.block.1.layer.1.DenseReluDense.wi.weight', 'extractor.block.9.layer.0.SelfAttention.v.weight', 'extractor.block.0.layer.0.SelfAttention.o.weight', 'extractor.block.0.layer.0.SelfAttention.q.weight', 'extractor.block.3.layer.1.layer_norm.weight', 'extractor.block.11.layer.0.layer_norm.weight', 'extractor.block.11.layer.1.DenseReluDense.wi.weight', 'extractor.block.7.layer.1.DenseReluDense.wi.weight', 'extractor.block.7.layer.0.SelfAttention.o.weight', 'extractor.block.11.layer.0.SelfAttention.q.weight', 'extractor.block.10.layer.0.SelfAttention.q.weight', 'extractor.block.8.layer.1.DenseReluDense.wi.weight', 'extractor.block.10.layer.1.DenseReluDense.wo.weight', 'extractor.block.0.layer.0.SelfAttention.k.weight', 'extractor.block.0.layer.1.DenseReluDense.wo.weight', 'extractor.block.11.layer.0.SelfAttention.k.weight', 'extractor.block.10.layer.1.layer_norm.weight', 'extractor.block.5.layer.1.layer_norm.weight', 'extractor.block.8.layer.0.SelfAttention.o.weight', 'extractor.block.2.layer.0.layer_norm.weight', 'extractor.block.10.layer.0.SelfAttention.k.weight', 'extractor.block.3.layer.0.SelfAttention.k.weight', 'extractor.block.5.layer.0.layer_norm.weight', 'extractor.block.8.layer.0.layer_norm.weight', 'extractor.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'extractor.block.9.layer.1.DenseReluDense.wo.weight', 'extractor.block.4.layer.0.SelfAttention.k.weight', 'extractor.block.5.layer.0.SelfAttention.o.weight', 'extractor.block.9.layer.1.DenseReluDense.wi.weight', 'extractor.block.4.layer.0.layer_norm.weight', 'extractor.block.4.layer.1.DenseReluDense.wi.weight', 'extractor.block.3.layer.0.SelfAttention.q.weight', 'extractor.block.11.layer.0.SelfAttention.o.weight', 'extractor.block.1.layer.0.SelfAttention.o.weight', 'extractor.block.6.layer.0.SelfAttention.o.weight', 'extractor.block.9.layer.1.layer_norm.weight', 'extractor.block.3.layer.1.DenseReluDense.wi.weight', 'extractor.block.10.layer.0.SelfAttention.o.weight', 'extractor.block.11.layer.0.SelfAttention.v.weight', 'extractor.block.5.layer.0.SelfAttention.v.weight', 'extractor.block.4.layer.1.DenseReluDense.wo.weight', 'extractor.block.4.layer.0.SelfAttention.o.weight', 'extractor.block.0.layer.1.layer_norm.weight', 'extractor.block.8.layer.0.SelfAttention.k.weight', 'extractor.block.2.layer.0.SelfAttention.v.weight', 'extractor.block.6.layer.1.DenseReluDense.wi.weight', 'extractor.block.3.layer.0.SelfAttention.o.weight', 'extractor.block.1.layer.0.SelfAttention.k.weight', 'extractor.block.2.layer.0.SelfAttention.q.weight', 'extractor.block.3.layer.0.SelfAttention.v.weight', 'extractor.block.3.layer.1.DenseReluDense.wo.weight', 'extractor.block.1.layer.0.SelfAttention.q.weight', 'extractor.block.8.layer.0.SelfAttention.q.weight', 'extractor.block.6.layer.0.SelfAttention.k.weight', 'extractor.block.2.layer.0.SelfAttention.k.weight', 'extractor.block.6.layer.1.DenseReluDense.wo.weight', 'extractor.block.7.layer.0.SelfAttention.q.weight', 'extractor.block.5.layer.0.SelfAttention.q.weight', 'extractor.block.5.layer.1.DenseReluDense.wi.weight', 'extractor.block.8.layer.1.layer_norm.weight', 'extractor.block.4.layer.0.SelfAttention.q.weight', 'extractor.embed_tokens.weight', 'extractor.block.1.layer.0.layer_norm.weight', 'extractor.block.6.layer.1.layer_norm.weight', 'extractor.block.5.layer.0.SelfAttention.k.weight', 'extractor.block.1.layer.1.DenseReluDense.wo.weight', 'extractor.block.8.layer.0.SelfAttention.v.weight', 'extractor.block.4.layer.1.layer_norm.weight', 'extractor.block.0.layer.0.SelfAttention.v.weight', 'extractor.block.4.layer.0.SelfAttention.v.weight', 'extractor.block.6.layer.0.layer_norm.weight', 'extractor.block.0.layer.0.layer_norm.weight', 'extractor.block.11.layer.1.layer_norm.weight', 'extractor.block.2.layer.0.SelfAttention.o.weight', 'extractor.block.7.layer.0.layer_norm.weight', 'extractor.block.1.layer.0.SelfAttention.v.weight', 'extractor.block.7.layer.0.SelfAttention.k.weight', 'extractor.block.9.layer.0.SelfAttention.q.weight', 'extractor.block.7.layer.1.layer_norm.weight', 'extractor.block.6.layer.0.SelfAttention.v.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\n","  | Name | Type                                    | Params\n","-----------------------------------------------------------------\n","0 | net  | T5ForConditionalGenerationWithExtractor | 332 M \n","-----------------------------------------------------------------\n","332 M     Trainable params\n","0         Non-trainable params\n","332 M     Total params\n","1,330.128 Total estimated model params size (MB)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d0f16f1fffe547358894479697e6f3e5","version_major":2,"version_minor":0},"text/plain":["Validation sanity check: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"73f09069949e46cd9fe8cf354c961bc7","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py:688: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n","  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"]}],"source":["model = TextSettrModel()\n","module = AmazonDataModule()\n","# checkpoint_callback = pl.callbacks.ModelCheckpoint(dirpath=root, filename='{epoch}')\n","checkpoint_callback = pl.callbacks.ModelCheckpoint(monitor=\"val_loss\")\n","trainer = Trainer(max_epochs = 10, gpus=1, default_root_dir=root, val_check_interval=0.25)\n","trainer.fit(model,module)\n","# model.net.cuda()"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":165,"status":"ok","timestamp":1646888281565,"user":{"displayName":"Xiyan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcg993ydhhc_E_jLjU0Fbj_ESzMgkFXC4i6rHZEA=s64","userId":"16542303003688506111"},"user_tz":480},"id":"6k31qPwHMLUX","outputId":"76962f3c-6e46-4a34-fce7-820e1054f31d"},"outputs":[{"data":{"text/plain":["T5ForConditionalGenerationWithExtractor(\n","  (shared): Embedding(32128, 768)\n","  (encoder): T5Stack(\n","    (embed_tokens): Embedding(32128, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (2): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (3): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (4): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (5): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (6): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (7): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (8): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (9): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (10): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (11): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (extractor): T5Stack(\n","    (embed_tokens): Embedding(32128, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (2): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (3): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (4): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (5): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (6): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (7): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (8): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (9): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (10): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (11): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): T5Stack(\n","    (embed_tokens): Embedding(32128, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (2): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (3): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (4): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (5): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (6): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (7): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (8): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (9): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (10): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (11): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",")"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["model.net"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":243},"executionInfo":{"elapsed":5010,"status":"ok","timestamp":1646888261406,"user":{"displayName":"Xiyan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcg993ydhhc_E_jLjU0Fbj_ESzMgkFXC4i6rHZEA=s64","userId":"16542303003688506111"},"user_tz":480},"id":"JewFvfsmG9Qh","outputId":"1aae2ae1-0d0c-425a-e35a-72c096295607"},"outputs":[],"source":["peek_output(\"This was a thought-provoking read\", \"\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":174},"executionInfo":{"elapsed":650,"status":"ok","timestamp":1646888262053,"user":{"displayName":"Xiyan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcg993ydhhc_E_jLjU0Fbj_ESzMgkFXC4i6rHZEA=s64","userId":"16542303003688506111"},"user_tz":480},"id":"dDxw6gNBHaRq","outputId":"531b5867-684a-457d-f7a7-6f4956611c52"},"outputs":[],"source":["formal_examplars = [\"This was a remarkably thought-provoking read.\",\n","                  \"It is certainly amongst my favorites.\"\n","                  \"We humbly request your presence at our gala on the 12th.\"]\n","informal_examplars = [\"reading this rly makes u think\",\n","                      \"Its def one of my favs\",\n","                      \"come swing by our bbq next week if ya can make it\"]\n","formal_input = \"I hereby commit to never purchase anything from this institution in the future.\"\n","lambda_factor = 6\n","peek_transfer_output(formal_input, informal_examplars, formal_examplars)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1095,"status":"ok","timestamp":1646888263146,"user":{"displayName":"Xiyan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcg993ydhhc_E_jLjU0Fbj_ESzMgkFXC4i6rHZEA=s64","userId":"16542303003688506111"},"user_tz":480},"id":"FDCZW0sVd6Is","outputId":"abd6f168-530d-4eb9-d43b-d676212cf1d9"},"outputs":[],"source":["formal_examplars = [\"This was a remarkably thought-provoking read.\",\n","                  \"It is certainly amongst my favorites.\"\n","                  \"We humbly request your presence at our gala on the 12th.\"]\n","informal_examplars = [\"reading this rly makes u think\",\n","                      \"Its def one of my favs\",\n","                      \"come swing by our bbq next week if ya can make it\"]\n","formal_input = \"I couldn’t figure out what the author was trying to say.\"\n","lambda_factor = 4\n","peek_transfer_output(formal_input, formal_examplars, informal_examplars),peek_transfer_output(formal_input, informal_examplars, formal_examplars)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1229,"status":"ok","timestamp":1646888264373,"user":{"displayName":"Xiyan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcg993ydhhc_E_jLjU0Fbj_ESzMgkFXC4i6rHZEA=s64","userId":"16542303003688506111"},"user_tz":480},"id":"AoNy2olqLmNe","outputId":"17a38551-830a-4379-9f57-910fd81ddaca"},"outputs":[],"source":["orig_ex = [          \n","\"No thank you, I'd prefer not to.\",\n","\"This game could have been better designed.\",\n","\"Do you know why they might have delayed the launch?\",\n","\"Sorry, I wasn' certain if you were joking.\"\n","]\n","\n","targ_ex = [\n","\"Hell no, you can't make me do that.\",\n","\"This game is such a piece of garbage!\",\n","\"Why in god's name would they delay the damn launch? Are you frigging kidding me?\"\n","]\n","\n","sent_ex = \"My favorate movie is\"\n","lambda_factor = 6\n","peek_transfer_output(sent_ex, targ_ex, orig_ex), peek_transfer_output(sent_ex, orig_ex, targ_ex)"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":12704,"status":"ok","timestamp":1646888277075,"user":{"displayName":"Xiyan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcg993ydhhc_E_jLjU0Fbj_ESzMgkFXC4i6rHZEA=s64","userId":"16542303003688506111"},"user_tz":480},"id":"7eoXxWaDbipq"},"outputs":[],"source":["model.net.save_pretrained(\"check\")\n","model.net.save_pretrained(root + \"/check2\")"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1646888277595,"user":{"displayName":"Xiyan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghcg993ydhhc_E_jLjU0Fbj_ESzMgkFXC4i6rHZEA=s64","userId":"16542303003688506111"},"user_tz":480},"id":"5srJUDxCrHwE"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNU3gDtwo+z3jme6aIzuMmF","collapsed_sections":[],"machine_shape":"hm","name":"text_settr.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"024e775bf4b54a969537b3a8b7fa4254":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_160b824ba95e4781abd186745f276dff","placeholder":"​","style":"IPY_MODEL_b916434bb5fd47de823893a7afa565d8","value":" 2/2 [00:01&lt;00:00,  1.30it/s]"}},"04d7d09c85d54ed6a705e1d80ebe0b7c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"091a52c8cf2347b4a32b28f0caade351":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3068cd5617c944e3aac4a9743daeac44","IPY_MODEL_5e7cd241a7da4e279a2f824575352000","IPY_MODEL_141d9220abcd427dbf67af00e1081c0f"],"layout":"IPY_MODEL_854140efaafa42e483b7892f9afac023"}},"0f8e95ac21c54b7595be6902f2e0d3c1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13b6a56e9cfb491dbbeb0657b67d46ad":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"141d9220abcd427dbf67af00e1081c0f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a91709688baf4a0a8a9f853dc41a2e8d","placeholder":"​","style":"IPY_MODEL_531f7016aefd421780aaf594b72f55dd","value":" 850M/850M [00:23&lt;00:00, 40.6MB/s]"}},"14a72691b6194e8c8d22922754b2a278":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4466b35bcd9145b481faeb56e5044319","placeholder":"​","style":"IPY_MODEL_2c968e30e00d4a25a3193d58d61df6d8","value":"Downloading: 100%"}},"160b824ba95e4781abd186745f276dff":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"271237b386024094b62c297e31ba1605":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2c968e30e00d4a25a3193d58d61df6d8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3068cd5617c944e3aac4a9743daeac44":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_83b81b4255cd4fbcab46b2cd5aa5fe35","placeholder":"​","style":"IPY_MODEL_573ec4b28bc54604aa187b824d9e84be","value":"Downloading: 100%"}},"30b700830b22427bb9b6c9baf531754f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e7b62fcda1cd4ad89d6acb9894224c84","IPY_MODEL_942817bb615f43b6bbef153607d1726c","IPY_MODEL_43502962ed2443308cac3cab014fc884"],"layout":"IPY_MODEL_c52ad3a5e491402ca0450e98223c5f92"}},"359ce540ac3a4627926c0ba579b422be":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f9577e12bcc4bc88970a8bd44dac74e","placeholder":"​","style":"IPY_MODEL_a810f3d48c6d48f19cdfcb327c6c8a70","value":" 1.32M/1.32M [00:00&lt;00:00, 1.97MB/s]"}},"3dc0a2213d05478abefb1fb0a7181696":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3edf04ef76ec43ba87f721c180b82c6d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ebc57df86d64e96b99a49e3362c5ccc","placeholder":"​","style":"IPY_MODEL_cdb6ce95b17641e99b2c492be55f7761","value":"Downloading: 100%"}},"43502962ed2443308cac3cab014fc884":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_13b6a56e9cfb491dbbeb0657b67d46ad","placeholder":"​","style":"IPY_MODEL_4e5f3ad65ba2424c8916492d6b988ed1","value":" 773k/773k [00:00&lt;00:00, 3.05MB/s]"}},"4371e711262f4b63956645b2516bd300":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4466b35bcd9145b481faeb56e5044319":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4551bee7755048c5b319ba2d3b91af66":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46a79c6e290842afaf2e82ef09ebbc14":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"49c63bb85d87413eaa2e70a26b5c41c5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49f17e67c08d4a2db23f75a66e9451b9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_04d7d09c85d54ed6a705e1d80ebe0b7c","placeholder":"​","style":"IPY_MODEL_960b230b6d0e40368093c0a7406481f4","value":" 0/53880 [00:00&lt;?, ?it/s]"}},"4b7300c59877494ea7433181920f6102":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b76e4af25d042ed9b1a84d7e6106e48":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4d2f9bdc3e414e10961415c5bc665728":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_d1af4f7e7dcf4bd69d5e89526b783c83","max":53880,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bb4fdab530e645aa9756417d65320238","value":0}},"4e5f3ad65ba2424c8916492d6b988ed1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5155c1279a704fe787d16e47fddfa5a9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_14a72691b6194e8c8d22922754b2a278","IPY_MODEL_e1ba5f052f404c2cadf36e857f1b0ac4","IPY_MODEL_359ce540ac3a4627926c0ba579b422be"],"layout":"IPY_MODEL_5633c4e2d47b47f5b26303dc06857e01"}},"531f7016aefd421780aaf594b72f55dd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5633c4e2d47b47f5b26303dc06857e01":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"573ec4b28bc54604aa187b824d9e84be":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5c795c4c3aba4e6ba45d9e713ec0a4bd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c7aa58d9650740aaabb35426796c0e12","placeholder":"​","style":"IPY_MODEL_46a79c6e290842afaf2e82ef09ebbc14","value":"Validation sanity check: 100%"}},"5e7cd241a7da4e279a2f824575352000":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd37662034814ed1a0bf4297f18fa444","max":891691430,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8f09e9fdac4c4258816911943a9279fd","value":891691430}},"60e23a09cf9e4dd48ef2ba97ee07793d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b7300c59877494ea7433181920f6102","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c3e243fa2fa9457aa431e14b312617ec","value":2}},"6aaacde2a2844526b01af7ee0021951d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3edf04ef76ec43ba87f721c180b82c6d","IPY_MODEL_c101d8e6036d45fdb7eb14e698b0511e","IPY_MODEL_f442b9ace69049aba9f77ed66d51f90c"],"layout":"IPY_MODEL_a60431b5009e4972990d8075a169eeab"}},"6ebc57df86d64e96b99a49e3362c5ccc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73f09069949e46cd9fe8cf354c961bc7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bd808ebcf0434eafb9cac74610d9a0b1","IPY_MODEL_4d2f9bdc3e414e10961415c5bc665728","IPY_MODEL_49f17e67c08d4a2db23f75a66e9451b9"],"layout":"IPY_MODEL_98a7180bf665423485a89e392f0fa97a"}},"7f9577e12bcc4bc88970a8bd44dac74e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83b81b4255cd4fbcab46b2cd5aa5fe35":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"854140efaafa42e483b7892f9afac023":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f09e9fdac4c4258816911943a9279fd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"942817bb615f43b6bbef153607d1726c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_aab12219030f411da25047b71a28d569","max":791656,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4b76e4af25d042ed9b1a84d7e6106e48","value":791656}},"960b230b6d0e40368093c0a7406481f4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"98a7180bf665423485a89e392f0fa97a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"a60431b5009e4972990d8075a169eeab":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6f1fad5e5ca4f11993ee5a693168a71":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"a810f3d48c6d48f19cdfcb327c6c8a70":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a91709688baf4a0a8a9f853dc41a2e8d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aab12219030f411da25047b71a28d569":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac79efaeb91b468d995c588eebc7eb19":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ad99ced523024b98a360345fa8f1af17":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b916434bb5fd47de823893a7afa565d8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bb4fdab530e645aa9756417d65320238":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bd808ebcf0434eafb9cac74610d9a0b1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4551bee7755048c5b319ba2d3b91af66","placeholder":"​","style":"IPY_MODEL_e5aebbc19cbf43d593089426f3f1a94c","value":"Epoch 0:   0%"}},"c101d8e6036d45fdb7eb14e698b0511e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f8e95ac21c54b7595be6902f2e0d3c1","max":1199,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ac79efaeb91b468d995c588eebc7eb19","value":1199}},"c3e243fa2fa9457aa431e14b312617ec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c52ad3a5e491402ca0450e98223c5f92":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7aa58d9650740aaabb35426796c0e12":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cdb6ce95b17641e99b2c492be55f7761":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d0f16f1fffe547358894479697e6f3e5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5c795c4c3aba4e6ba45d9e713ec0a4bd","IPY_MODEL_60e23a09cf9e4dd48ef2ba97ee07793d","IPY_MODEL_024e775bf4b54a969537b3a8b7fa4254"],"layout":"IPY_MODEL_a6f1fad5e5ca4f11993ee5a693168a71"}},"d1af4f7e7dcf4bd69d5e89526b783c83":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1ba5f052f404c2cadf36e857f1b0ac4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3dc0a2213d05478abefb1fb0a7181696","max":1389353,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ad99ced523024b98a360345fa8f1af17","value":1389353}},"e5aebbc19cbf43d593089426f3f1a94c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e7b62fcda1cd4ad89d6acb9894224c84":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_49c63bb85d87413eaa2e70a26b5c41c5","placeholder":"​","style":"IPY_MODEL_271237b386024094b62c297e31ba1605","value":"Downloading: 100%"}},"f442b9ace69049aba9f77ed66d51f90c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4371e711262f4b63956645b2516bd300","placeholder":"​","style":"IPY_MODEL_fec2a8f9f2e94c9d97e46bb070aa1a02","value":" 1.17k/1.17k [00:00&lt;00:00, 39.1kB/s]"}},"fd37662034814ed1a0bf4297f18fa444":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fec2a8f9f2e94c9d97e46bb070aa1a02":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
